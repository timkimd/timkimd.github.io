<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tim Kim</title>
  
  <meta name="author" content="Tim Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="cQVvLBPnyQIS9_eaNXtLtm2WadNt4zgIx5M6kTWy79o" />
  <meta name="description" content="Personal website of Timothy Doyeon Kim, PhD student at the Princeton Neuroscience Institute">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="favicon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tim Kim</name>
              </p>
              <p>I recently started as a <a target="_blank" rel="noopener noreferrer" href="https://alleninstitute.org/careers/internships-and-postbac/shanahan-foundation-fellowship/">Shanahan Foundation Fellow</a> at the Allen Institute and the University of Washington. <br><br>I received my PhD from Princeton University, where I was advised by <a target="_blank" rel="noopener noreferrer" href="http://brodylab.org/">Carlos Brody</a> and collaborated with <a target="_blank" rel="noopener noreferrer" href="https://pillowlab.princeton.edu/">Jonathan Pillow</a>. During my PhD, I developed unsupervised methods for discovering interpretable latent dynamics underlying neural population activity. I completed my undergraduate studies at the University of Pennsylvania, where I worked with <a target="_blank" rel="noopener noreferrer" href="https://www.med.upenn.edu/goldlab/">Josh Gold</a>.

	      <br><br>
		      
		You can get in touch with me at <a src="mailto:timkimd@uw.edu">timkimd@uw.edu</a>.
		  
		    </p>
              <p style="text-align:center">
                <a target="_blank" rel="noopener noreferrer" href="https://github.com/timkimd/">github</a> / <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=FTWUPusAAAAJ&hl=en">google scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
	      <a href="profile.jpg"><img style="width:70%;max-width:70%" alt="profile photo" src="profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications & Preprints</heading>&nbsp; (* indicates equal contribution)
		    <ul>
		    <li><strong>Kim, T.D.</strong>, Luo, T.Z., Can, T., Krishnamurthy, K., Pillow, J.W., Brody, C.D. (2025). Flow-field inference from neural data using deep recurrent networks. <em>Proceedings of the 42nd International Conference on Machine Learning (ICML)</em>. <br>
		    [<a onclick=showAbstract(5)>abstract</a> | <a target="_blank" rel="noopener noreferrer" href="https://openreview.net/forum?id=ZLC4B9oQWX">link</a> | <a target="_blank" rel="noopener noreferrer" href="/papers/Kim_2023_FINDR.txt">bibtex</a>]
		    <div id="paper5" style="display:none">
    			<p><b>Abstract:</b> Neural computations underlying processes such as decision-making, working memory, and motor control are thought to emerge from neural population dynamics. But estimating these dynamics remains a significant challenge. Here we introduce Flow-field Inference from Neural Data using deep Recurrent networks (FINDR), an unsupervised deep learning method for inferring low-dimensional, nonlinear, stochastic dynamics underlying neural population activity. Using spike train data from frontal brain regions of rats performing an auditory decision-making task, we demonstrate that FINDR performs competitively with existing methods in capturing the heterogeneous responses of individual neurons. When trained to disentangle task-relevant and irrelevant activity, FINDR uncovers interpretable low-dimensional dynamics. These dynamics can be visualized as flow fields and attractors, enabling direct tests of attractor-based theories of neural computation. We suggest FINDR as a powerful method for revealing the low-dimensional task-relevant dynamics of neural populations and their associated computations. </p>
  		    </div>
		    </li><br>
		    <li>
		    Luo, T.Z.*, <strong>Kim, T.D.</strong>*, Gupta D., Bondy, A.G., Kopec, C.D., Elliot, V.A., DePasquale, B., Brody, C.D. (2023). Transitions in dynamical regime and neural mode underlie perceptual decision-making. <em>bioRxiv</em>. <br>
		    [<a onclick=showAbstract(4)>abstract</a> | <a target="_blank" rel="noopener noreferrer" href="https://www.biorxiv.org/content/10.1101/2023.10.15.562427v4">link</a> | <a target="_blank" rel="noopener noreferrer" href="/papers/LuoKim_2023_noncanonical.txt">bibtex</a>]
		    <div id="paper4" style="display:none">
    			<p><b>Abstract:</b> Perceptual decision-making is the process by which an animal uses sensory stimuli to choose an action or mental proposition. This process is thought to be mediated by neurons organized as attractor networks. However, whether attractor dynamics underlie decision behavior and the complex neuronal responses remains unclear. Here we use an unsupervised, deep learning-based method to discover decision-related dynamics from the simultaneous activity of neurons in frontal cortex and striatum of rats while they accumulate pulsatile auditory evidence. We show that contrary to prevailing hypotheses, attractors play a role only after a transition from a regime in the dynamics that is strongly driven by inputs to one dominated by the intrinsic dynamics. The initial regime mediates evidence accumulation, and the subsequent intrinsic-dominant regime subserves decision commitment. This regime transition is coupled to a rapid reorganization in the representation of the decision process in the neural population (a change in the "neural mode" along which the process develops). A simplified model approximating the coupled transition in the dynamics and neural mode allows inferring, from each trial's neural activity, the internal decision commitment time in that trial, and captures diverse and complex single-neuron temporal profiles, such as ramping and stepping. It also captures trial-averaged curved trajectories, and reveals distinctions between brain regions. Our results show that the formation of a perceptual choice involves a rapid, coordinated transition in both the dynamical regime and the neural mode of the decision process, and suggest pairing deep learning and parsimonious models as a promising approach for understanding complex data. </p>
  		    </div>
		    </li><br>
		    <li>
		    <strong>Kim, T.D.</strong>, Can, T.*, Krishnamurthy, K.* (2023). Trainability, Expressivity and Interpretability in Gated Neural ODEs. <em>Proceedings of the 40th International Conference on Machine Learning (ICML)</em>. <br>
		    [<a onclick=showAbstract(3)>abstract</a> | <a target="_blank" rel="noopener noreferrer" href="https://proceedings.mlr.press/v202/kim23b.html">link</a> | <a target="_blank" rel="noopener noreferrer" href="/papers/Kim_ICML2023_gnODE.txt">bibtex</a>]
		    <div id="paper3" style="display:none">
    			<p><b>Abstract:</b> Understanding how the dynamics in biological and artificial neural networks implement the computations required for a task is a salient open question in machine learning and neuroscience. In particular, computations requiring complex memory storage and retrieval pose a significant challenge for these networks to implement or learn. Recently, a family of models described by neural ordinary differential equations (nODEs) has emerged as powerful dynamical neural network models capable of capturing complex dynamics. Here, we extend nODEs by endowing them with adaptive timescales using gating interactions. We refer to these as gated neural ODEs (gnODEs). Using a task that requires memory of continuous quantities, we demonstrate the inductive bias of the gnODEs to learn (approximate) continuous attractors. We further show how reduced-dimensional gnODEs retain their modeling power while greatly improving interpretability, even allowing explicit visualization of the structure of learned attractors. We introduce a novel measure of expressivity which probes the capacity of a neural network to generate complex trajectories. Using this measure, we explore how the phase-space dimension of the nODEs and the complexity of the function modeling the flow field contribute to expressivity. We see that a more complex function for modeling the flow field allows a lower-dimensional nODE to capture a given target dynamics. Finally, we demonstrate the benefit of gating in nODEs on several real-world tasks. </p>
  		    </div>
		    </li><br>
		    <li>
		    <strong>Kim, T.D.</strong>, Luo, T.Z., Pillow, J.W., Brody, C.D. (2021). Inferring latent dynamics underlying neural population activity via neural differential equations. <em>Proceedings of the 38th International Conference on Machine Learning (ICML)</em>. (<strong>long talk</strong>) <br>
		    [<a onclick=showAbstract(2)>abstract</a> | <a target="_blank" rel="noopener noreferrer" href="http://proceedings.mlr.press/v139/kim21h.html">link</a> | <a target="_blank" rel="noopener noreferrer" href="/papers/Kim_ICML2021_PLNDE.txt">bibtex</a>]
		    <div id="paper2" style="display:none">
    			<p><b>Abstract:</b> An important problem in systems neuroscience is to identify the latent dynamics underlying neural population activity. Here we address this problem by introducing a low-dimensional nonlinear model for latent neural population dynamics using neural ordinary differential equations (neural ODEs), with noisy sensory inputs and Poisson spike train outputs. We refer to this as the Poisson Latent Neural Differential Equations (PLNDE) model. We apply the PLNDE framework to a variety of synthetic datasets, and show that it accurately infers the phase portraits and fixed points of nonlinear systems augmented to produce spike train data, including the FitzHugh-Nagumo oscillator, a 3-dimensional nonlinear spiral, and a nonlinear sensory decision-making model with attractor dynamics. Our model significantly outperforms existing methods at inferring single-trial neural firing rates and the corresponding latent trajectories that generated them, especially in the regime where the spike counts and number of trials are low. We then apply our model to multi-region neural population recordings from medial frontal cortex of rats performing an auditory decision-making task. Our model provides a general, interpretable framework for investigating the neural mechanisms of decision-making and other cognitive computations through the lens of dynamical systems. </p>
  		    </div>
		    </li><br>
		    <li>
		    <strong>Kim, T.D.</strong>, Kabir, M., Gold, J.I. (2017). Coupled decision processes update and maintain saccadic prior in a dynamic environment. <em>Journal of Neuroscience</em>. <br>
		    [<a onclick=showAbstract(1)>abstract</a> | <a target="_blank" rel="noopener noreferrer" href="https://www.jneurosci.org/content/37/13/3632.long">link</a> | <a target="_blank" rel="noopener noreferrer" href="/papers/Kim_JN2017.txt">bibtex</a>]
		    <div id="paper1" style="display:none">
    			<p><b>Abstract:</b> Much of what we know about how the brain forms decisions comes from studies of saccadic eye movements. However, saccadic decisions are often studied in isolation, which limits the insights that they can provide about real-world decisions with complex interdependencies. Here, we used a serial reaction time (RT) task to show that prior expectations affect RTs via interdependent, normative decision processes that operate within and across saccades. We found that human subjects performing the task generated saccades that were governed by a rise-to-threshold decision process with a starting point that reflected expected state-dependent transition probabilities. These probabilities depended on decisions about the current state (the correct target) that, under some conditions, required the accumulation of information across saccades. Without additional feedback, this information was provided by each saccadic decision threshold, which represented the total evidence in favor of the chosen target. Therefore, the output of the within-saccade process was used, not only to generate the saccade, but also to provide input to the across-saccade process. This across-saccade process, in turn, helped to set the starting point of the next within-saccade process. These results imply a novel role for functional information-processing loops in optimizing saccade generation in dynamic environments. </p>
  		    </div>
		    </li>
		    </ul>
            </td>
          </tr>
        </tbody></table>
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent Conference Abstracts</heading>
		    <ul>
		    <li><strong>Kim, T.D.</strong>, Luo, T.Z., Can, T., Krishnamurthy, K., Pillow, J.W., Brody, C.D. (2024, poster). Flow-field inference from neural data using deep recurrent networks. <em>Computational and Systems Neuroscience (Cosyne)</em>.
		    </li><br>
		    <li>Luo, T.Z.*, <strong>Kim, T.D.</strong>*, Gupta D., Bondy, A.G., Kopec, C.D., Elliot, V.A., DePasquale, B., Brody, C.D. (2024, <strong>talk</strong>). Transitions in dynamical regime and neural mode underlie perceptual decision-making. <em>Computational and Systems Neuroscience (Cosyne)</em>.
		    </li><br>
		    <li><strong>Kim, T.D.</strong>, Luo, T.Z., Can, T., Krishnamurthy, K., Pillow, J.W., Brody, C.D. (2023, <strong>talk</strong>). Flow-field inference from neural data using deep recurrent networks. <em>Bernstein Conference</em>.
		    </li><br>
		    <li>Luo, T.Z., <strong>Kim, T.D.</strong>, DePasquale, B., Brody, C.D. (2023, poster). Distinct mechanisms for evidence accumulation and choice memory explain diverse neuronal dynamics. <em>Computational and Systems Neuroscience (Cosyne)</em>.
		    </li><br>
		    <li><strong>Kim, T.D.</strong>, Can, T.*, Krishnamurthy, K.* (2022, poster). Learning and Shaping Manifold Attractors for Computation in Gated Neural ODEs. <em>Symmetry and Geometry in Neural Representations Workshop at Neural Information Processing Systems (NeurIPS)</em>.
		    </li><br>
		    <li>Luo, T.Z., <strong>Kim, T.D.</strong>, DePasquale, B., Brody, C.D. (2022, poster). Inference of the time-varying relationship between spike trains and a latent decision variable. <em>Computational and Systems Neuroscience (Cosyne)</em>.
		    </li><br>
		    <li><strong>Kim, T.D.</strong>, Luo, T.Z., Pillow, J.W., Brody, C.D. (2021, poster). Inferring latent dynamics underlying neural population activity via neural differential equations. <em>Computational and Systems Neuroscience (Cosyne)</em>.
		    </li>
		    </ul>
            </td>
          </tr>
        </tbody></table>
          
 
      </td>
    </tr>
  </table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right" style="color:#BEBEBE">
          <font size="2">             
          Template from <a target="_blank" rel="noopener noreferrer" href="https://jonbarron.info/">Jon Barron's website</a>
    </font>
        </p>
        </td>
      </tr>
      </table>

<!-- For showing/hiding abstracts:-->
<script>
function showAbstract(id) {
  var x = document.getElementById('paper' + id);
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
</script>
</body>

</html>
